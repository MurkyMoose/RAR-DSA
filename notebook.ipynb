{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950971d7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tools.basic import  map_label, SUBKEY_TO_PARENT, group_root_subkeys_under_correct_parents\n",
    "\n",
    "from typing import Any, Dict\n",
    "from definitions.coding_manuals import  system_prompt_whole\n",
    "from definitions.instructions import inference_instructions_whole\n",
    "from definitions.models import AttributionResponse\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import asyncio\n",
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "import matplotlib.pyplot as plt\n",
    "from src.dependencies import client\n",
    "from src.reflexion import process_entry_with_reflect\n",
    "from src.experts import process_entry\n",
    "from src.utils import merge_multiple_ai_runs, comparison_mode, matrix, calculate_f1_scores, calculate_f1_scores_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997a8dd",
   "metadata": {},
   "source": [
    "# Set up environment, client and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "with open(\"data/human_coding/human_coding_with_transcript.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    human_coding_with_transcript = json.load(f)\n",
    "\n",
    "categories = ['Int_U', 'Int_D','Con_UU', 'Con_CR', 'LOC_E', 'LOC_IGL', 'LOC_IBU', 'Perm_FC', 'Perm_SU']\n",
    "output_folder = \"ai_json_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cb755",
   "metadata": {},
   "source": [
    "# RUN A: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57889cd5",
   "metadata": {},
   "source": [
    "## Elaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbfa71",
   "metadata": {},
   "source": [
    "In Run A, for each transcript, we run inference using PASS manual 3 times each at temperature 1 (only temp valid) for o4-mini-2025-04-16 to account for non-deterministic nature of responses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff54092",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"o4-mini-2025-04-16\"\n",
    "temp = 1\n",
    "run_segment = 'A'\n",
    "runs = 3\n",
    "\n",
    "print(f\"Running with temperature: {temp}\")\n",
    "\n",
    "run_id = f\"Run_{run_segment}_model_{model_name}_temp_{temp}\"\n",
    "for index in  tqdm(range(len(human_coding_with_transcript))):\n",
    "      entry = human_coding_with_transcript[index]\n",
    "      file_name = f\"{entry['subject_code']}.json\"\n",
    "\n",
    "      file_folder = f\"{output_folder}/{run_id}\"\n",
    "      os.makedirs(file_folder, exist_ok=True)\n",
    "\n",
    "      file_path = f\"{file_folder}/{file_name}\"\n",
    "      if file_name in os.listdir(file_folder):\n",
    "            continue\n",
    "      \n",
    "      run_compiled = []\n",
    "\n",
    "      for run_index in range(runs):\n",
    "            completion = client.chat.completions.parse(\n",
    "                  model=model_name,\n",
    "                  messages=[\n",
    "                        {\"role\": \"system\",\n",
    "                        \"content\": system_prompt_whole\n",
    "                              },\n",
    "                              \n",
    "                        {\"role\": \"user\",\n",
    "                        \"content\": \"Test Case Interview Transcript: \\n\"+ entry['transcript']\n",
    "                              },\n",
    "\n",
    "                        {\"role\": \"user\",\n",
    "                              \"content\":  \"INSTRUCTIONS: \"+inference_instructions_whole\n",
    "\n",
    "                        },\n",
    "                  ],\n",
    "                  response_format=AttributionResponse,\n",
    "                  temperature=temp,\n",
    "                  top_p=1,\n",
    "                  presence_penalty=0,\n",
    "                  frequency_penalty=0,\n",
    "                  seed=42)\n",
    "            \n",
    "            time.sleep(1)\n",
    "            run_compiled.append(json.loads(completion.choices[0].message.content))\n",
    "\n",
    "      with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(run_compiled, f, indent=2, ensure_ascii=False)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e034e6",
   "metadata": {},
   "source": [
    "## Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "model_name = \"o4-mini-2025-04-16\"\n",
    "run_segment = 'A'\n",
    "run_id = f\"Run_{run_segment}_model_{model_name}_temp_{temp}\"\n",
    "path = f\"{output_folder}/{run_id}\"\n",
    "\n",
    "run_A_f1 = calculate_f1_scores_from_path(human_coding_with_transcript, path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_A_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6347e9f",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7b448",
   "metadata": {},
   "source": [
    "baseline run o4-mini-2025-04-16 at temp 1 yields 'micro_f1': 0.442"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70fe57",
   "metadata": {},
   "source": [
    "# RUN B: Split by Experts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cfedc",
   "metadata": {},
   "source": [
    "## Elaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c04b25",
   "metadata": {},
   "source": [
    "In Run B, for each transcript, we run inference using PASS manual 3 times each at temperature 1 for o4-mini-2025-04-16.\n",
    "- Instead of running inference of all dimensions at once on each call, each call only focuses on 1 dimension. Results are aggregated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc902f4",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2912c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"o4-mini-2025-04-16\"\n",
    "temp = 1\n",
    "runs = 3\n",
    "run_id = f\"Run_B_model_{model_name}_temp_{temp}_experts\"\n",
    "\n",
    "# ---- Run ----\n",
    "async def main():\n",
    "    for index in tqdm(range(len(human_coding_with_transcript))):\n",
    "        entry = human_coding_with_transcript[index]\n",
    "        #print(entry['subject_code'])\n",
    "        file_name = f\"{entry['subject_code']}.json\"\n",
    "        file_folder = f\"{output_folder}/{run_id}\"\n",
    "        os.makedirs(file_folder, exist_ok=True)\n",
    "        file_path = os.path.join(file_folder, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            #print(f\"Skipping {file_name}, already exists.\")\n",
    "            continue\n",
    "\n",
    "        await process_entry(entry, run_id, model_name, temp, file_path, runs)\n",
    "        await asyncio.sleep(60)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4860f",
   "metadata": {},
   "source": [
    "## Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "model_name = \"o4-mini-2025-04-16\"\n",
    "run_segment = 'B'\n",
    "run_id = f\"Run_{run_segment}_model_{model_name}_temp_{temp}_experts\"\n",
    "path = f\"{output_folder}/{run_id}\"\n",
    "\n",
    "run_B_f1 = calculate_f1_scores_from_path(human_coding_with_transcript, path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604660bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_B_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c9e7a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e33fb1",
   "metadata": {},
   "source": [
    "Splitting by experts yields improvement of 'micro_f1': 0.536 compared to baseline of 'micro_f1': 0.442"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca20573",
   "metadata": {},
   "source": [
    "# RUN C: Split by Experts + React"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4986308a",
   "metadata": {},
   "source": [
    "## Elaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe7852",
   "metadata": {},
   "source": [
    "In Run C, each expert's response on a transcript has 2 rounds of reflection and revision. Flag attribution misclassifications, Suggest additions/removals, Ensure inclusion/exclusion criteria are met. Output from 2nd revision used as final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88529b8c",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"o4-mini-2025-04-16\"\n",
    "temp = 1\n",
    "run_id = f\"Run_C_model_{model_name}_temp_{temp}_experts_reflexion\"\n",
    "\n",
    "async def main():\n",
    "    for index in tqdm(range(len(human_coding_with_transcript))):\n",
    "        entry = human_coding_with_transcript[index]\n",
    "        #print(entry['subject_code'])\n",
    "        file_name = f\"{entry['subject_code']}.json\"\n",
    "        file_folder = f\"{output_folder}/{run_id}\"\n",
    "        os.makedirs(file_folder, exist_ok=True)\n",
    "        file_path = os.path.join(file_folder, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            #print(f\"Skipping {file_name}, already exists.\")\n",
    "            continue\n",
    "\n",
    "        await process_entry_with_reflect(entry, run_id, model_name, temp, False)\n",
    "        await asyncio.sleep(60)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b739c",
   "metadata": {},
   "source": [
    "## Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36822a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "model_name = \"o4-mini-2025-04-16\"\n",
    "run_id = f\"Run_C_model_{model_name}_temp_{temp}_experts_reflexion\"\n",
    "path = f\"{output_folder}/{run_id}\"\n",
    "\n",
    "run_C_f1 = calculate_f1_scores_from_path(human_coding_with_transcript, path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_C_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9f5c3e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9c676",
   "metadata": {},
   "source": [
    "Reflexion yields improvement of 'micro_f1': 0.565 compared to previous best of 'micro_f1': 0.536."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c2b04",
   "metadata": {},
   "source": [
    "# Run D: with retrieval of references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0458bd9",
   "metadata": {},
   "source": [
    "## Elaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07e657",
   "metadata": {},
   "source": [
    "Prior to 1st reflection, insert 3 most similiar transcript by embeddings and include human codings as few shot examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cf350",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"o4-mini-2025-04-16\"\n",
    "temp = 1\n",
    "run_id = f\"Run_D_model_{model_name}_temp_{temp}_experts_reflexion_with_references\"\n",
    "\n",
    "async def main():\n",
    "    for index in tqdm(range(len(human_coding_with_transcript))):\n",
    "        entry = human_coding_with_transcript[index]\n",
    "        #print(entry['subject_code'])\n",
    "        file_name = f\"{entry['subject_code']}.json\"\n",
    "        file_folder = f\"{output_folder}/{run_id}\"\n",
    "        os.makedirs(file_folder, exist_ok=True)\n",
    "        file_path = os.path.join(file_folder, file_name)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            #print(f\"Skipping {file_name}, already exists.\")\n",
    "            continue\n",
    "\n",
    "        await process_entry_with_reflect(entry, run_id, model_name, temp, True)\n",
    "        await asyncio.sleep(60)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9efb554",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dfaab75",
   "metadata": {},
   "source": [
    "## Calculate F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be754af",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "model_name = \"o4-mini-2025-04-16\"\n",
    "run_id = f\"Run_D_model_{model_name}_temp_{temp}_experts_reflexion_with_references\"\n",
    "path = f\"{output_folder}/{run_id}\"\n",
    "\n",
    "run_D_f1 = calculate_f1_scores_from_path(human_coding_with_transcript, path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_D_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0cbbb3",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c53adb",
   "metadata": {},
   "source": [
    "References yields improvement of 'micro_f1': 0.572 compared to previous best of 'micro_f1': 0.565."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a28d120",
   "metadata": {},
   "source": [
    "# Graph comparison with Chatgpt Interface results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "paths = [[\"chatgpt\",\"ai_json_output/chatgpt_baseline\"], [\"o4-mini\",\"ai_json_output/Run_D_model_o4-mini-2025-04-16_temp_1_experts_reflexion_with_references\"]]\n",
    "for threshold in [95, 90, 85, 80, 75, 70, 65, 60, 55, 50]:\n",
    "    out[str(threshold)] = {}\n",
    "    for path_info in paths:\n",
    "        all_matrixes = []\n",
    "        path = path_info[1]\n",
    "        for oneJson in os.listdir(path):\n",
    "            if oneJson.split(\".\")[0] in [\"C1012M\", \"C678M\", \"C642F\", \"EARC003M\", \"EARC004M\", \"C639M\", \"C616M\",\n",
    "        \"EARC002M\", \"EARC006M\", \"C1000F\", \"C1000M\", \"C1036F\", \"C1036M\", \"C1031F\",\n",
    "        \"C1031M\", \"C1009F\", \"C1057F\", \"C1057M\", \"C662M\", \"C629M\", \"C625M\", \"C613F\",\n",
    "        \"C613M\", \"EARC011M\", \"EARC013F\", \"EARC013M\", \"EARC014M\", \"EARC027M\",\n",
    "        \"U165F\", \"U165M\", \"EARC092M\", \"EARC116M\"]:\n",
    "                continue\n",
    "            pathfile = f\"{path}/{oneJson}\"\n",
    "\n",
    "            if '.json' not in oneJson:\n",
    "                continue\n",
    "            with open(pathfile, \"r\", encoding=\"utf-8\") as f:\n",
    "                inference = json.load(f)\n",
    "\n",
    "            \n",
    "            if path_info[0]=='o4-mini':\n",
    "                ai_entry = comparison_mode(merge_multiple_ai_runs(inference))\n",
    "            else:\n",
    "                ai_entry = (inference)\n",
    "\n",
    "            human_entry = [a for a in human_coding_with_transcript if a[\"subject_code\"] ==oneJson.split(\".\")[0] ][0]\n",
    "\n",
    "            one_entry_matrixes = {}\n",
    "\n",
    "            for acat in categories:\n",
    "                acat_human = 'Human_'+acat\n",
    "                acat_ai = 'AI_'+acat\n",
    "                one_entry_matrixes[acat] = matrix(human_entry[acat_human], ai_entry[acat_ai], threshold )\n",
    "\n",
    "            all_matrixes.append(one_entry_matrixes)\n",
    "        \n",
    "        out[str(threshold)][path_info[0]] = calculate_f1_scores(all_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the x-axis to go from 100 to 50\n",
    "\n",
    "x_reversed = sorted(out.keys(), key=lambda k: int(k), reverse=True)\n",
    "chat_macro = [out[k]['chatgpt']['macro_f1'] for k in x_reversed]\n",
    "chat_micro = [out[k]['chatgpt']['micro_f1'] for k in x_reversed]\n",
    "agent_macro = [out[k]['o4-mini']['macro_f1'] for k in x_reversed]\n",
    "agent_micro = [out[k]['o4-mini']['micro_f1'] for k in x_reversed]\n",
    "\n",
    "# Plotting with reversed x-axis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_reversed, chat_macro, label='Chat Interface - Macro F1', marker='o')\n",
    "plt.plot(x_reversed, chat_micro, label='Chat Interface - Micro F1', marker='o')\n",
    "plt.plot(x_reversed, agent_macro, label='Approach D - Macro F1', marker='s')\n",
    "plt.plot(x_reversed, agent_micro, label='Approach D - Micro F1', marker='s')\n",
    "\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Macro and Micro F1 Scores by Threshold (Descending)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venve2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
